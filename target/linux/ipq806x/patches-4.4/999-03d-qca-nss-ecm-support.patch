--- a/include/linux/mroute.h	2018-12-13 16:21:37.000000000 +0800
+++ b/include/linux/mroute.h	2019-06-25 08:02:17.821366838 +0800
@@ -104,4 +104,42 @@
 extern int ipmr_get_route(struct net *net, struct sk_buff *skb,
 			  __be32 saddr, __be32 daddr,
 			  struct rtmsg *rtm, int nowait, u32 portid);
+
+#define IPMR_MFC_EVENT_UPDATE   1
+#define IPMR_MFC_EVENT_DELETE   2
+
+/*
+ * Callback to registered modules in the event of updates to a multicast group
+ */
+typedef void (*ipmr_mfc_event_offload_callback_t)(__be32 origin, __be32 group,
+						  u32 max_dest_dev,
+						  u32 dest_dev_idx[],
+						  u8 op);
+
+/*
+ * Register the callback used to inform offload modules when updates occur to
+ * MFC. The callback is registered by offload modules
+ */
+extern bool ipmr_register_mfc_event_offload_callback(
+			ipmr_mfc_event_offload_callback_t mfc_offload_cb);
+
+/*
+ * De-Register the callback used to inform offload modules when updates occur
+ * to MFC
+ */
+extern void ipmr_unregister_mfc_event_offload_callback(void);
+
+/*
+ * Find the destination interface list, given a multicast group and source
+ */
+extern int ipmr_find_mfc_entry(struct net *net, __be32 origin, __be32 group,
+				 u32 max_dst_cnt, u32 dest_dev[]);
+
+/*
+ * Out-of-band multicast statistics update for flows that are offloaded from
+ * Linux
+ */
+extern int ipmr_mfc_stats_update(struct net *net, __be32 origin, __be32 group,
+				 u64 pkts_in, u64 bytes_in,
+				 u64 pkts_out, u64 bytes_out);
 #endif
--- a/include/linux/mroute6.h	2018-12-13 16:21:37.000000000 +0800
+++ b/include/linux/mroute6.h	2019-06-25 08:02:17.821366838 +0800
@@ -113,10 +113,51 @@ struct mfc6_cache {
 
 #define MFC_ASSERT_THRESH (3*HZ)		/* Maximal freq. of asserts */
 
+#define IP6MR_MFC_EVENT_UPDATE   1
+#define IP6MR_MFC_EVENT_DELETE   2
+
 struct rtmsg;
 extern int ip6mr_get_route(struct net *net, struct sk_buff *skb,
 			   struct rtmsg *rtm, int nowait, u32 portid);
 
+/*
+ * Callback to registered modules in the event of updates to a multicast group
+ */
+typedef void (*ip6mr_mfc_event_offload_callback_t)(struct in6_addr *origin,
+						   struct in6_addr *group,
+						   u32 max_dest_dev,
+						   u32 dest_dev_idx[],
+						   uint8_t op);
+
+/*
+ * Register the callback used to inform offload modules when updates occur
+ * to MFC. The callback is registered by offload modules
+ */
+extern bool ip6mr_register_mfc_event_offload_callback(
+			ip6mr_mfc_event_offload_callback_t mfc_offload_cb);
+
+/*
+ * De-Register the callback used to inform offload modules when updates occur
+ * to MFC
+ */
+extern void ip6mr_unregister_mfc_event_offload_callback(void);
+
+/*
+ * Find the destination interface list given a multicast group and source
+ */
+extern int ip6mr_find_mfc_entry(struct net *net, struct in6_addr *origin,
+				struct in6_addr *group, u32 max_dst_cnt,
+				u32 dest_dev[]);
+
+/*
+ * Out-of-band multicast statistics update for flows that are offloaded from
+ * Linux
+ */
+extern int ip6mr_mfc_stats_update(struct net *net, struct in6_addr *origin,
+				  struct in6_addr *group, uint64_t pkts_in,
+				  uint64_t bytes_in, uint64_t pkts_out,
+				  uint64_t bytes_out);
+
 #ifdef CONFIG_IPV6_MROUTE
 extern struct sock *mroute6_socket(struct net *net, struct sk_buff *skb);
 extern int ip6mr_sk_done(struct sock *sk);
--- a/net/ipv4/ipmr.c	2019-06-29 16:00:51.167313179 +0800
+++ b/net/ipv4/ipmr.c	2019-06-25 08:02:20.833366838 +0800
@@ -137,6 +137,9 @@ static void mroute_netlink_event(struct
 				 int cmd);
 static void mroute_clean_tables(struct mr_table *mrt, bool all);
 static void ipmr_expire_process(unsigned long arg);
+static struct mfc_cache *ipmr_cache_find(struct mr_table *mrt, __be32 origin,
+					 __be32 mcastgrp);
+static ipmr_mfc_event_offload_callback_t __rcu ipmr_mfc_event_offload_callback;
 
 #ifdef CONFIG_IP_MROUTE_MULTIPLE_TABLES
 #define ipmr_for_each_table(mrt, net) \
@@ -227,6 +230,78 @@ static int ipmr_rule_fill(struct fib_rul
 	return 0;
 }
 
+/* ipmr_sync_entry_update()
+ * Call the registered offload callback to report an update to a multicast
+ * route entry. The callback receives the list of destination interfaces and
+ * the interface count
+ */
+static void ipmr_sync_entry_update(struct mr_table *mrt,
+				   struct mfc_cache *cache)
+{
+	int vifi, dest_if_count = 0;
+	u32 dest_dev[MAXVIFS];
+	__be32  origin;
+	__be32  group;
+	ipmr_mfc_event_offload_callback_t offload_update_cb_f;
+
+	memset(dest_dev, 0, sizeof(dest_dev));
+
+	origin = cache->mfc_origin;
+	group = cache->mfc_mcastgrp;
+
+	read_lock(&mrt_lock);
+	for (vifi = 0; vifi < cache->mfc_un.res.maxvif; vifi++) {
+		if (!((cache->mfc_un.res.ttls[vifi] > 0) &&
+		      (cache->mfc_un.res.ttls[vifi] < 255))) {
+			continue;
+		}
+		if (dest_if_count == MAXVIFS) {
+			read_unlock(&mrt_lock);
+			return;
+		}
+
+		if (!VIF_EXISTS(mrt, vifi)) {
+			read_unlock(&mrt_lock);
+			return;
+		}
+		dest_dev[dest_if_count] = mrt->vif_table[vifi].dev->ifindex;
+		dest_if_count++;
+	}
+	read_unlock(&mrt_lock);
+
+	rcu_read_lock();
+	offload_update_cb_f = rcu_dereference(ipmr_mfc_event_offload_callback);
+
+	if (!offload_update_cb_f) {
+		rcu_read_unlock();
+		return;
+	}
+
+	offload_update_cb_f(group, origin, dest_if_count, dest_dev,
+			    IPMR_MFC_EVENT_UPDATE);
+	rcu_read_unlock();
+}
+
+/* ipmr_sync_entry_delete()
+ * Call the registered offload callback to inform of a multicast route entry
+ * delete event
+ */
+static void ipmr_sync_entry_delete(u32 origin, u32 group)
+{
+	ipmr_mfc_event_offload_callback_t offload_update_cb_f;
+
+	rcu_read_lock();
+	offload_update_cb_f = rcu_dereference(ipmr_mfc_event_offload_callback);
+
+	if (!offload_update_cb_f) {
+		rcu_read_unlock();
+		return;
+	}
+
+	offload_update_cb_f(group, origin, 0, NULL, IPMR_MFC_EVENT_DELETE);
+	rcu_read_unlock();
+}
+
 static const struct fib_rules_ops __net_initconst ipmr_rules_ops_template = {
 	.family		= RTNL_FAMILY_IPMR,
 	.rule_size	= sizeof(struct ipmr_rule),
@@ -241,6 +316,150 @@ static const struct fib_rules_ops __net_
 	.owner		= THIS_MODULE,
 };
 
+/* ipmr_register_mfc_event_offload_callback()
+ * Register the IPv4 Multicast update offload callback with IPMR
+ */
+bool ipmr_register_mfc_event_offload_callback(
+		ipmr_mfc_event_offload_callback_t mfc_offload_cb)
+{
+	ipmr_mfc_event_offload_callback_t offload_update_cb_f;
+
+	rcu_read_lock();
+	offload_update_cb_f = rcu_dereference(ipmr_mfc_event_offload_callback);
+
+	if (offload_update_cb_f) {
+		rcu_read_unlock();
+		return false;
+	}
+
+	rcu_assign_pointer(ipmr_mfc_event_offload_callback, mfc_offload_cb);
+	rcu_read_unlock();
+	return true;
+}
+EXPORT_SYMBOL(ipmr_register_mfc_event_offload_callback);
+
+/* ipmr_unregister_mfc_event_offload_callback()
+ * De-register the IPv4 Multicast update offload callback with IPMR
+ */
+void ipmr_unregister_mfc_event_offload_callback(void)
+{
+	rcu_read_lock();
+	rcu_assign_pointer(ipmr_mfc_event_offload_callback, NULL);
+	rcu_read_unlock();
+}
+EXPORT_SYMBOL(ipmr_unregister_mfc_event_offload_callback);
+
+/* ipmr_find_mfc_entry()
+ * Returns destination interface list for a particular multicast flow, and
+ * the number of interfaces in the list
+ */
+int ipmr_find_mfc_entry(struct net *net, __be32 origin, __be32 group,
+			u32 max_dest_cnt, u32 dest_dev[])
+{
+	int vifi, dest_if_count = 0;
+	struct mr_table *mrt;
+	struct mfc_cache *cache;
+
+	mrt = ipmr_get_table(net, RT_TABLE_DEFAULT);
+	if (!mrt)
+		return -ENOENT;
+
+	rcu_read_lock();
+	cache = ipmr_cache_find(mrt, origin, group);
+	if (!cache) {
+		rcu_read_unlock();
+		return -ENOENT;
+	}
+
+	read_lock(&mrt_lock);
+	for (vifi = 0; vifi < cache->mfc_un.res.maxvif; vifi++) {
+		if (!((cache->mfc_un.res.ttls[vifi] > 0) &&
+		      (cache->mfc_un.res.ttls[vifi] < 255))) {
+			continue;
+		}
+
+		/* We have another valid destination interface entry. Check if
+		 * the number of the destination interfaces for the route is
+		 * exceeding the size of the array given to us
+		 */
+		if (dest_if_count == max_dest_cnt) {
+			read_unlock(&mrt_lock);
+			rcu_read_unlock();
+			return -EINVAL;
+		}
+
+		if (!VIF_EXISTS(mrt, vifi)) {
+			read_unlock(&mrt_lock);
+			rcu_read_unlock();
+			return -EINVAL;
+		}
+
+		dest_dev[dest_if_count] = mrt->vif_table[vifi].dev->ifindex;
+		dest_if_count++;
+	}
+	read_unlock(&mrt_lock);
+	rcu_read_unlock();
+
+	return dest_if_count;
+}
+EXPORT_SYMBOL(ipmr_find_mfc_entry);
+
+/* ipmr_mfc_stats_update()
+ * Update the MFC/VIF statistics for offloaded flows
+ */
+int ipmr_mfc_stats_update(struct net *net, __be32 origin, __be32 group,
+			  u64 pkts_in, u64 bytes_in,
+			  u64 pkts_out, u64 bytes_out)
+{
+	int vif, vifi;
+	struct mr_table *mrt;
+	struct mfc_cache *cache;
+
+	mrt = ipmr_get_table(net, RT_TABLE_DEFAULT);
+	if (!mrt)
+		return -ENOENT;
+
+	rcu_read_lock();
+	cache = ipmr_cache_find(mrt, origin, group);
+	if (!cache) {
+		rcu_read_unlock();
+		return -ENOENT;
+	}
+
+	vif = cache->mfc_parent;
+
+	read_lock(&mrt_lock);
+	if (!VIF_EXISTS(mrt, vif)) {
+		read_unlock(&mrt_lock);
+		rcu_read_unlock();
+		return -EINVAL;
+	}
+
+	mrt->vif_table[vif].pkt_in += pkts_in;
+	mrt->vif_table[vif].bytes_in += bytes_in;
+	cache->mfc_un.res.pkt  += pkts_out;
+	cache->mfc_un.res.bytes += bytes_out;
+
+	for (vifi = cache->mfc_un.res.minvif;
+			vifi < cache->mfc_un.res.maxvif; vifi++) {
+		if ((cache->mfc_un.res.ttls[vifi] > 0) &&
+		    (cache->mfc_un.res.ttls[vifi] < 255)) {
+			if (!VIF_EXISTS(mrt, vifi)) {
+				read_unlock(&mrt_lock);
+				rcu_read_unlock();
+				return -EINVAL;
+			}
+			mrt->vif_table[vifi].pkt_out += pkts_out;
+			mrt->vif_table[vifi].bytes_out += bytes_out;
+		}
+	}
+	read_unlock(&mrt_lock);
+	rcu_read_unlock();
+
+	return 0;
+}
+EXPORT_SYMBOL(ipmr_mfc_stats_update);
+
 static int __net_init ipmr_rules_init(struct net *net)
 {
 	struct fib_rules_ops *ops;
@@ -1108,6 +1327,7 @@ static int ipmr_mfc_delete(struct mr_tab
 {
 	int line;
 	struct mfc_cache *c, *next;
+	u32 origin, group;
 
 	line = MFC_HASH(mfc->mfcc_mcastgrp.s_addr, mfc->mfcc_origin.s_addr);
 
@@ -1115,9 +1335,14 @@ static int ipmr_mfc_delete(struct mr_tab
 		if (c->mfc_origin == mfc->mfcc_origin.s_addr &&
 		    c->mfc_mcastgrp == mfc->mfcc_mcastgrp.s_addr &&
 		    (parent == -1 || parent == c->mfc_parent)) {
+			origin = c->mfc_origin;
+			group = c->mfc_mcastgrp;
 			list_del_rcu(&c->list);
 			mroute_netlink_event(mrt, c, RTM_DELROUTE);
 			ipmr_cache_free(c);
+
+			/* Inform offload modules of the delete event */
+			ipmr_sync_entry_delete(origin, group);
 			return 0;
 		}
 	}
@@ -1153,6 +1378,9 @@ static int ipmr_mfc_add(struct net *net,
 			c->mfc_flags |= MFC_STATIC;
 		write_unlock_bh(&mrt_lock);
 		mroute_netlink_event(mrt, c, RTM_NEWROUTE);
+
+		/* Inform offload modules of the update event */
+		ipmr_sync_entry_update(mrt, c);
 		return 0;
 	}
 
--- a/net/ipv6/ip6mr.c	2019-06-29 16:00:51.171313179 +0800
+++ b/net/ipv6/ip6mr.c	2019-06-25 08:02:20.969366838 +0800
@@ -122,6 +122,11 @@ static int ip6mr_rtm_dumproute(struct sk
 			       struct netlink_callback *cb);
 static void mroute_clean_tables(struct mr6_table *mrt, bool all);
 static void ipmr_expire_process(unsigned long arg);
+static struct mfc6_cache *ip6mr_cache_find(struct mr6_table *mrt,
+					   const struct in6_addr *origin,
+					   const struct in6_addr *mcastgrp);
+static ip6mr_mfc_event_offload_callback_t __rcu
+				ip6mr_mfc_event_offload_callback;
 
 #ifdef CONFIG_IPV6_MROUTE_MULTIPLE_TABLES
 #define ip6mr_for_each_table(mrt, net) \
@@ -342,6 +347,82 @@ static void ip6mr_free_table(struct mr6_
 	kfree(mrt);
 }
 
+/* ip6mr_sync_entry_update()
+ * Call the registered offload callback to report an update to a multicast
+ * route entry. The callback receives the list of destination interfaces and
+ * the interface count
+ */
+static void ip6mr_sync_entry_update(struct mr6_table *mrt,
+				    struct mfc6_cache *cache)
+{
+	int vifi, dest_if_count = 0;
+	u32 dest_dev[MAXMIFS];
+	struct in6_addr mc_origin, mc_group;
+	ip6mr_mfc_event_offload_callback_t offload_update_cb_f;
+
+	memset(dest_dev, 0, sizeof(dest_dev));
+
+	read_lock(&mrt_lock);
+
+	for (vifi = 0; vifi < cache->mfc_un.res.maxvif; vifi++) {
+		if (!((cache->mfc_un.res.ttls[vifi] > 0) &&
+		      (cache->mfc_un.res.ttls[vifi] < 255))) {
+			continue;
+		}
+
+		if (dest_if_count == MAXMIFS) {
+			read_unlock(&mrt_lock);
+			return;
+		}
+
+		if (!MIF_EXISTS(mrt, vifi)) {
+			read_unlock(&mrt_lock);
+			return;
+		}
+
+		dest_dev[dest_if_count] = mrt->vif6_table[vifi].dev->ifindex;
+		dest_if_count++;
+	}
+
+	memcpy(&mc_origin, &cache->mf6c_origin, sizeof(struct in6_addr));
+	memcpy(&mc_group, &cache->mf6c_mcastgrp, sizeof(struct in6_addr));
+	read_unlock(&mrt_lock);
+
+	rcu_read_lock();
+	offload_update_cb_f = rcu_dereference(ip6mr_mfc_event_offload_callback);
+
+	if (!offload_update_cb_f) {
+		rcu_read_unlock();
+		return;
+	}
+
+	offload_update_cb_f(&mc_group, &mc_origin, dest_if_count, dest_dev,
+			    IP6MR_MFC_EVENT_UPDATE);
+	rcu_read_unlock();
+}
+
+/* ip6mr_sync_entry_delete()
+ * Call the registered offload callback to inform of a multicast route entry
+ * delete event
+ */
+static void ip6mr_sync_entry_delete(struct in6_addr *mc_origin,
+				    struct in6_addr *mc_group)
+{
+	ip6mr_mfc_event_offload_callback_t offload_update_cb_f;
+
+	rcu_read_lock();
+	offload_update_cb_f = rcu_dereference(ip6mr_mfc_event_offload_callback);
+
+	if (!offload_update_cb_f) {
+		rcu_read_unlock();
+		return;
+	}
+
+	offload_update_cb_f(mc_group, mc_origin, 0, NULL,
+			    IP6MR_MFC_EVENT_DELETE);
+	rcu_read_unlock();
+}
+
 #ifdef CONFIG_PROC_FS
 
 struct ipmr_mfc_iter {
@@ -775,6 +856,145 @@ failure:
 }
 #endif
 
+/* ip6mr_register_mfc_event_offload_callback()
+ * Register the IPv6 multicast update callback for offload modules
+ */
+bool ip6mr_register_mfc_event_offload_callback(
+		ip6mr_mfc_event_offload_callback_t mfc_offload_cb)
+{
+	ip6mr_mfc_event_offload_callback_t offload_update_cb_f;
+
+	rcu_read_lock();
+	offload_update_cb_f = rcu_dereference(ip6mr_mfc_event_offload_callback);
+
+	if (offload_update_cb_f) {
+		rcu_read_unlock();
+		return false;
+	}
+
+	rcu_assign_pointer(ip6mr_mfc_event_offload_callback, mfc_offload_cb);
+	rcu_read_unlock();
+	return true;
+}
+EXPORT_SYMBOL(ip6mr_register_mfc_event_offload_callback);
+
+/* ip6mr_unregister_mfc_event_offload_callback()
+ * De-register the IPv6 multicast update callback for offload modules
+ */
+void ip6mr_unregister_mfc_event_offload_callback(void)
+{
+	rcu_read_lock();
+	rcu_assign_pointer(ip6mr_mfc_event_offload_callback, NULL);
+	rcu_read_unlock();
+}
+EXPORT_SYMBOL(ip6mr_unregister_mfc_event_offload_callback);
+
+/* ip6mr_find_mfc_entry()
+ * Return the destination interface list for a particular multicast flow, and
+ * the number of interfaces in the list
+ */
+int ip6mr_find_mfc_entry(struct net *net, struct in6_addr *origin,
+			 struct in6_addr *group, u32 max_dest_cnt,
+			 u32 dest_dev[])
+{
+	int vifi, dest_if_count = 0;
+	struct mr6_table *mrt;
+	struct mfc6_cache *cache;
+
+	mrt = ip6mr_get_table(net, RT6_TABLE_DFLT);
+	if (!mrt)
+		return -ENOENT;
+
+	read_lock(&mrt_lock);
+	cache = ip6mr_cache_find(mrt, origin, group);
+	if (!cache) {
+		read_unlock(&mrt_lock);
+		return -ENOENT;
+	}
+
+	for (vifi = 0; vifi < cache->mfc_un.res.maxvif; vifi++) {
+		if (!((cache->mfc_un.res.ttls[vifi] > 0) &&
+		      (cache->mfc_un.res.ttls[vifi] < 255))) {
+			continue;
+		}
+
+		/* We have another valid destination interface entry. Check if
+		 * the number of the destination interfaces for the route is
+		 * exceeding the size of the array given to us
+		 */
+		if (dest_if_count == max_dest_cnt) {
+			read_unlock(&mrt_lock);
+			return -EINVAL;
+		}
+
+		if (!MIF_EXISTS(mrt, vifi)) {
+			read_unlock(&mrt_lock);
+			return -EINVAL;
+		}
+
+		dest_dev[dest_if_count] = mrt->vif6_table[vifi].dev->ifindex;
+		dest_if_count++;
+	}
+	read_unlock(&mrt_lock);
+
+	return dest_if_count;
+}
+EXPORT_SYMBOL(ip6mr_find_mfc_entry);
+
+/* ip6mr_mfc_stats_update()
+ * Update the MFC/VIF statistics for offloaded flows
+ */
+int ip6mr_mfc_stats_update(struct net *net, struct in6_addr *origin,
+			   struct in6_addr *group, u64 pkts_in,
+			   u64 bytes_in, uint64_t pkts_out,
+			   u64 bytes_out)
+{
+	int vif, vifi;
+	struct mr6_table *mrt;
+	struct mfc6_cache *cache;
+
+	mrt = ip6mr_get_table(net, RT6_TABLE_DFLT);
+
+	if (!mrt)
+		return -ENOENT;
+
+	read_lock(&mrt_lock);
+	cache = ip6mr_cache_find(mrt, origin, group);
+	if (!cache) {
+		read_unlock(&mrt_lock);
+		return -ENOENT;
+	}
+
+	vif = cache->mf6c_parent;
+
+	if (!MIF_EXISTS(mrt, vif)) {
+		read_unlock(&mrt_lock);
+		return -EINVAL;
+	}
+
+	mrt->vif6_table[vif].pkt_in += pkts_in;
+	mrt->vif6_table[vif].bytes_in += bytes_in;
+	cache->mfc_un.res.pkt += pkts_out;
+	cache->mfc_un.res.bytes += bytes_out;
+
+	for (vifi = cache->mfc_un.res.minvif;
+			vifi < cache->mfc_un.res.maxvif; vifi++) {
+		if ((cache->mfc_un.res.ttls[vifi] > 0) &&
+		    (cache->mfc_un.res.ttls[vifi] < 255)) {
+			if (!MIF_EXISTS(mrt, vifi)) {
+				read_unlock(&mrt_lock);
+				return -EINVAL;
+			}
+			mrt->vif6_table[vifi].pkt_out += pkts_out;
+			mrt->vif6_table[vifi].bytes_out += bytes_out;
+		}
+	}
+
+	read_unlock(&mrt_lock);
+	return 0;
+}
+EXPORT_SYMBOL(ip6mr_mfc_stats_update);
+
 /*
  *	Delete a VIF entry
  */
@@ -1308,6 +1528,7 @@ static int ip6mr_mfc_delete(struct mr6_t
 {
 	int line;
 	struct mfc6_cache *c, *next;
+	struct in6_addr mc_origin, mc_group;
 
 	line = MFC6_HASH(&mfc->mf6cc_mcastgrp.sin6_addr, &mfc->mf6cc_origin.sin6_addr);
 
@@ -1316,12 +1537,20 @@ static int ip6mr_mfc_delete(struct mr6_t
 		    ipv6_addr_equal(&c->mf6c_mcastgrp,
 				    &mfc->mf6cc_mcastgrp.sin6_addr) &&
 		    (parent == -1 || parent == c->mf6c_parent)) {
+			memcpy(&mc_origin, &c->mf6c_origin,
+			       sizeof(struct in6_addr));
+			memcpy(&mc_group, &c->mf6c_mcastgrp,
+			       sizeof(struct in6_addr));
+
 			write_lock_bh(&mrt_lock);
 			list_del(&c->list);
 			write_unlock_bh(&mrt_lock);
 
 			mr6_netlink_event(mrt, c, RTM_DELROUTE);
 			ip6mr_cache_free(c);
+
+			/* Inform offload modules of the delete event */
+			ip6mr_sync_entry_delete(&mc_origin, &mc_group);
 			return 0;
 		}
 	}
@@ -1490,6 +1719,9 @@ static int ip6mr_mfc_add(struct net *net
 			c->mfc_flags |= MFC_STATIC;
 		write_unlock_bh(&mrt_lock);
 		mr6_netlink_event(mrt, c, RTM_NEWROUTE);
+
+		/* Inform offload modules of the update event */
+		ip6mr_sync_entry_update(mrt, c);
 		return 0;
 	}
 
